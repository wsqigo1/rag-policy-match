import logging
import time
import re
from typing import List, Dict, Any, Optional
from collections import defaultdict
from datetime import datetime

from models import (
    QueryRequest, QueryResponse, MatchResult, RetrievalResult,
    BasicMatchRequest, PreciseMatchRequest, CompanyInfo, PolicyMatch, OneClickMatchResponse,
    PolicyEligibilityRequest, PolicyEligibilityResponse,
    RequirementStatus, ConditionAnalysis, StructuredPolicy, EnhancedRequirementStatus
)
from advanced_retriever import AdvancedRetriever
from llm_manager import LLMManager
from config import Config

logger = logging.getLogger(__name__)

class StructuredFieldMatcher:
    """ç»“æ„åŒ–å­—æ®µåŒ¹é…å™¨"""
    
    def __init__(self, llm_manager: LLMManager):
        self.llm_manager = llm_manager
        
        # å­—æ®µåŒ¹é…æƒé‡
        self.field_weights = {
            'service_object': 0.25,      # æœåŠ¡å¯¹è±¡æƒé‡æœ€é«˜
            'tool_category': 0.20,       # å·¥å…·åˆ†ç±»
            'condition_requirements': 0.20, # æ¡ä»¶è¦æ±‚
            'service_content': 0.15,     # æœåŠ¡å†…å®¹
            'issuing_agency': 0.10,      # å‘æ–‡æœºæ„
            'time_frequency': 0.05,      # æ—¶é—´é¢‘åº¦
            'policy_level': 0.05         # æ”¿ç­–çº§åˆ«
        }

    async def calculate_field_match_score(self, company_info: CompanyInfo, 
                                         policy: StructuredPolicy) -> Dict[str, float]:
        """è®¡ç®—å„å­—æ®µåŒ¹é…åˆ†æ•°"""
        scores = {}
        
        # 1. æœåŠ¡å¯¹è±¡åŒ¹é…
        scores['service_object'] = await self._match_service_object(
            company_info, policy.service_object
        )
        
        # 2. å·¥å…·åˆ†ç±»åŒ¹é…
        scores['tool_category'] = await self._match_tool_category(
            company_info, policy.tool_category
        )
        
        # 3. æ¡ä»¶è¦æ±‚åŒ¹é…
        scores['condition_requirements'] = await self._match_conditions(
            company_info, policy.condition_requirements
        )
        
        # 4. æœåŠ¡å†…å®¹åŒ¹é…
        scores['service_content'] = await self._match_service_content(
            company_info, policy.service_content
        )
        
        # 5. å‘æ–‡æœºæ„åŒ¹é…ï¼ˆæ ¹æ®ä¼ä¸šæ‰€åœ¨åœ°ï¼‰
        scores['issuing_agency'] = self._match_issuing_agency(
            company_info, policy.issuing_agency
        )
        
        # 6. æ—¶é—´é¢‘åº¦åŒ¹é…
        scores['time_frequency'] = self._match_time_frequency(
            policy.time_frequency
        )
        
        # 7. æ”¿ç­–çº§åˆ«åŒ¹é…
        scores['policy_level'] = self._match_policy_level(
            company_info, policy.policy_level
        )
        
        return scores

    async def _match_service_object(self, company_info: CompanyInfo, 
                                   service_object: Optional[str]) -> float:
        """åŒ¹é…æœåŠ¡å¯¹è±¡"""
        if not service_object:
            return 0.5
        
        # ä¼ä¸šè§„æ¨¡åŒ¹é…
        scale_keywords = {
            'åˆåˆ›': ['åˆåˆ›', 'åˆ›ä¸š', 'æ–°è®¾ç«‹', 'æˆç«‹ä¸æ»¡'],
            'å°å‹': ['å°å‹', 'å°å¾®', 'ä¸­å°', 'å°ä¼ä¸š'],
            'ä¸­å‹': ['ä¸­å‹', 'ä¸­ç­‰è§„æ¨¡'],
            'å¤§å‹': ['å¤§å‹', 'å¤§ä¼ä¸š', 'é¾™å¤´'],
            'é«˜æ–°': ['é«˜æ–°æŠ€æœ¯', 'é«˜ç§‘æŠ€', 'æŠ€æœ¯å…ˆè¿›'],
            'ä¸“ç²¾ç‰¹æ–°': ['ä¸“ç²¾ç‰¹æ–°', 'éšå½¢å† å†›'],
        }
        
        score = 0.0
        service_lower = service_object.lower()
        
        # æ ¹æ®å…¬å¸è§„æ¨¡è¯„åˆ†
        if company_info.scale:
            scale_lower = company_info.scale.lower()
            for scale_type, keywords in scale_keywords.items():
                if scale_lower in scale_type.lower():
                    for keyword in keywords:
                        if keyword in service_lower:
                            score += 0.3
                            break
        
        # è¡Œä¸šåŒ¹é…
        if company_info.industry:
            industry_lower = company_info.industry.lower()
            if any(ind in service_lower for ind in industry_lower.split()):
                score += 0.4
        
        # ä¼ä¸šæ€§è´¨åŒ¹é…
        if company_info.enterprise_type:
            if company_info.enterprise_type.lower() in service_lower:
                score += 0.3
        
        return min(score, 1.0)

    async def _match_tool_category(self, company_info: CompanyInfo, 
                                  tool_category: Optional[str]) -> float:
        """åŒ¹é…å·¥å…·åˆ†ç±»"""
        if not tool_category:
            return 0.5
        
        # æ ¹æ®ä¼ä¸šéœ€æ±‚æ¨æ–­å·¥å…·åˆ†ç±»åå¥½
        category_preferences = {
            'èµ„é‡‘æ”¯æŒ': 0.8,  # å¤§å¤šæ•°ä¼ä¸šéƒ½éœ€è¦èµ„é‡‘æ”¯æŒ
            'æ”¿ç­–æ”¯æŒ': 0.6,
            'ç¨æ”¶ä¼˜æƒ ': 0.7,
            'å¹³å°æ”¯æŒ': 0.5,
            'äººæ‰æ”¯æŒ': 0.4
        }
        
        category_lower = tool_category.lower()
        
        # åŸºç¡€åŒ¹é…
        base_score = 0.5
        
        # ç‰¹å®šåŒ¹é…
        for category, preference in category_preferences.items():
            if category in category_lower:
                base_score = preference
                break
        
        # æ ¹æ®ä¼ä¸šæƒ…å†µè°ƒæ•´
        if company_info.scale == "åˆåˆ›ä¼ä¸š" and "èµ„é‡‘" in category_lower:
            base_score += 0.2
        
        if company_info.employees and company_info.employees < 50 and "äººæ‰" in category_lower:
            base_score += 0.2
        
        return min(base_score, 1.0)

    async def _match_conditions(self, company_info: CompanyInfo, 
                               conditions: Optional[str]) -> float:
        """åŒ¹é…æ¡ä»¶è¦æ±‚"""
        if not conditions:
            return 0.5
        
        # ä½¿ç”¨LLMåˆ†ææ¡ä»¶åŒ¹é…
        prompt = f"""
        åˆ†æä¼ä¸šæ˜¯å¦æ»¡è¶³æ”¿ç­–æ¡ä»¶è¦æ±‚ï¼Œè¿”å›åŒ¹é…åˆ†æ•°(0-1)å’Œåˆ†æè¯´æ˜ã€‚

        ä¼ä¸šä¿¡æ¯ï¼š
        - å…¬å¸åç§°ï¼š{company_info.company_name}
        - è¡Œä¸šï¼š{company_info.industry}
        - è§„æ¨¡ï¼š{company_info.scale}
        - å‘˜å·¥æ•°ï¼š{company_info.employees}
        - æ³¨å†Œèµ„æœ¬ï¼š{company_info.registered_capital}
        - å¹´è¥ä¸šé¢ï¼š{company_info.annual_revenue}

        æ”¿ç­–æ¡ä»¶è¦æ±‚ï¼š
        {conditions}

        è¯·åˆ†æä¼ä¸šæ˜¯å¦æ»¡è¶³è¿™äº›æ¡ä»¶ï¼Œç»™å‡º0-1çš„åŒ¹é…åˆ†æ•°ã€‚
        """
        
        try:
            response = await self.llm_manager.generate_policy_analysis(
                prompt, company_info.__dict__
            )
            
            # ä»å“åº”ä¸­æå–åˆ†æ•°
            score_match = re.search(r'(\d+\.?\d*)', response)
            if score_match:
                score = float(score_match.group(1))
                if score > 1:
                    score = score / 10  # å¦‚æœæ˜¯0-10åˆ†åˆ¶ï¼Œè½¬æ¢ä¸º0-1
                return min(score, 1.0)
            
        except Exception as e:
            logger.warning(f"LLM condition matching failed: {e}")
        
        # å¤‡ç”¨è§„åˆ™åŒ¹é…
        return self._rule_based_condition_match(company_info, conditions)

    def _rule_based_condition_match(self, company_info: CompanyInfo, 
                                   conditions: str) -> float:
        """åŸºäºè§„åˆ™çš„æ¡ä»¶åŒ¹é…"""
        score = 0.5
        conditions_lower = conditions.lower()
        
        # æ”¶å…¥æ¡ä»¶åŒ¹é…
        if company_info.annual_revenue:
            revenue_matches = re.findall(r'(\d+(?:\.\d+)?)\s*(?:ä¸‡å…ƒ|ä¸‡|äº¿å…ƒ|äº¿)', conditions_lower)
            if revenue_matches:
                required_revenue = float(revenue_matches[0])
                if 'äº¿' in conditions_lower:
                    required_revenue *= 10000
                
                if company_info.annual_revenue >= required_revenue:
                    score += 0.3
                elif company_info.annual_revenue >= required_revenue * 0.8:
                    score += 0.1
        
        # å‘˜å·¥æ•°æ¡ä»¶åŒ¹é…
        if company_info.employees:
            employee_matches = re.findall(r'(\d+)\s*(?:äºº|å)', conditions_lower)
            if employee_matches:
                required_employees = int(employee_matches[0])
                if company_info.employees >= required_employees:
                    score += 0.2
        
        return min(score, 1.0)

    async def _match_service_content(self, company_info: CompanyInfo, 
                                   service_content: Optional[str]) -> float:
        """åŒ¹é…æœåŠ¡å†…å®¹"""
        if not service_content:
            return 0.5
        
        # åŸºäºä¼ä¸šéœ€æ±‚åŒ¹é…æœåŠ¡å†…å®¹
        content_lower = service_content.lower()
        score = 0.5
        
        # æ ¹æ®ä¼ä¸šè§„æ¨¡æ¨æ–­éœ€æ±‚
        if company_info.scale == "åˆåˆ›ä¼ä¸š":
            if any(keyword in content_lower for keyword in ['å­µåŒ–', 'åˆ›ä¸š', 'å¯åŠ¨èµ„é‡‘', 'åˆæœŸæ”¯æŒ']):
                score += 0.3
        
        # æ ¹æ®è¡Œä¸šåŒ¹é…
        if company_info.industry:
            industry_lower = company_info.industry.lower()
            if any(ind in content_lower for ind in industry_lower.split()):
                score += 0.2
        
        return min(score, 1.0)

    def _match_issuing_agency(self, company_info: CompanyInfo, 
                             issuing_agency: Optional[str]) -> float:
        """åŒ¹é…å‘æ–‡æœºæ„"""
        if not issuing_agency:
            return 0.5
        
        # ç®€å•çš„åœ°åŸŸåŒ¹é…é€»è¾‘
        agency_lower = issuing_agency.lower()
        
        # å¦‚æœæ˜¯åŒ—äº¬çš„ä¼ä¸šï¼ŒåŒ—äº¬å¸‚æ”¿ç­–æ›´åŒ¹é…
        if 'åŒ—äº¬å¸‚' in agency_lower:
            return 0.8
        elif 'å›½åŠ¡é™¢' in agency_lower or 'å›½å®¶' in agency_lower:
            return 0.7  # å›½å®¶çº§æ”¿ç­–æ™®éé€‚ç”¨
        else:
            return 0.6

    def _match_time_frequency(self, time_frequency: Optional[str]) -> float:
        """åŒ¹é…æ—¶é—´é¢‘åº¦"""
        if not time_frequency:
            return 0.5
        
        time_lower = time_frequency.lower()
        
        # å¸¸å¹´å—ç†çš„æ”¿ç­–æ›´å¥½
        if 'å¸¸å¹´' in time_lower or 'éšæ—¶' in time_lower:
            return 0.9
        elif 'å®šæœŸ' in time_lower or 'æ‰¹æ¬¡' in time_lower:
            return 0.7
        else:
            return 0.5

    def _match_policy_level(self, company_info: CompanyInfo, 
                           policy_level: Optional[str]) -> float:
        """åŒ¹é…æ”¿ç­–çº§åˆ«"""
        if not policy_level:
            return 0.5
        
        # ä¸åŒçº§åˆ«æ”¿ç­–çš„ä¼˜å…ˆçº§
        level_scores = {
            'å›½å®¶çº§': 0.9,
            'å¸‚çº§': 0.8,
            'åŒºçº§': 0.7,
            'å…¶ä»–': 0.6
        }
        
        return level_scores.get(policy_level, 0.5)

class EnhancedPolicyMatcher:
    """å¢å¼ºçš„æ”¿ç­–åŒ¹é…å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self.retriever = AdvancedRetriever()
        self.llm_manager = LLMManager()
        self.field_matcher = StructuredFieldMatcher(self.llm_manager)
        
    async def initialize(self):
        """åˆå§‹åŒ–"""
        # AdvancedRetrieveræ²¡æœ‰initializeæ–¹æ³•ï¼Œä½¿ç”¨å»¶è¿ŸåŠ è½½
        # await self.retriever.initialize()
        await self.llm_manager.initialize()

    async def query_policies(self, request: QueryRequest) -> QueryResponse:
        """æŸ¥è¯¢æ”¿ç­–ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        start_time = datetime.now()
        
        try:
            # 1. æ™ºèƒ½æŸ¥è¯¢ç†è§£
            query_analysis = await self.llm_manager.understand_query(request.query)
            
            # 2. é«˜çº§æ£€ç´¢
            from advanced_retriever import AdvancedQueryRequest, RetrievalStrategy
            
            advanced_request = AdvancedQueryRequest(
                query=request.query,
                strategy=RetrievalStrategy.FULL_ADVANCED,
                company_context=request.company_info.__dict__ if request.company_info else None,
                top_k=request.top_k or 10,
                use_llm_enhancement=True,
                use_reranking=True
            )
            
            retrieval_response = await self.retriever.retrieve(advanced_request)
            retrieval_results = retrieval_response.results if retrieval_response.success else []
            
            # 3. ç»“æ„åŒ–å­—æ®µåŒ¹é…å’Œé‡æ’
            enhanced_results = []
            for result in retrieval_results:
                # æå–ç»“æ„åŒ–æ”¿ç­–ä¿¡æ¯
                if hasattr(result, 'metadata') and 'structured_policy' in result.metadata:
                    structured_policy = StructuredPolicy(**result.metadata['structured_policy'])
                    
                    # è®¡ç®—å­—æ®µåŒ¹é…åˆ†æ•°
                    if request.company_info:
                        field_scores = await self.field_matcher.calculate_field_match_score(
                            request.company_info, structured_policy
                        )
                        
                        # è®¡ç®—æ€»åˆ†
                        total_score = sum(
                            score * self.field_matcher.field_weights.get(field, 0.1)
                            for field, score in field_scores.items()
                        )
                        
                        # ç»“åˆåŸå§‹ç›¸ä¼¼åº¦åˆ†æ•°
                        final_score = 0.6 * result.score + 0.4 * total_score
                        result.score = final_score
                        result.metadata['field_scores'] = field_scores
                        result.metadata['structured_analysis'] = True
                
                enhanced_results.append(result)
            
            # 4. æŒ‰æ–°åˆ†æ•°é‡æ–°æ’åº
            enhanced_results.sort(key=lambda x: x.score, reverse=True)
            
            # 5. ç”Ÿæˆä¸ªæ€§åŒ–æ¨è
            if request.company_info:
                personalized_summary = await self.llm_manager.generate_personalized_recommendation(
                    enhanced_results[:5], request.company_info
                )
            else:
                personalized_summary = "å»ºè®®æä¾›ä¼ä¸šä¿¡æ¯ä»¥è·å¾—ä¸ªæ€§åŒ–æ”¿ç­–æ¨èã€‚"
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return QueryResponse(
                results=enhanced_results,
                query_analysis=query_analysis,
                personalized_summary=personalized_summary,
                total_found=len(enhanced_results),
                processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"Enhanced policy query failed: {str(e)}")
            processing_time = (datetime.now() - start_time).total_seconds()
            return QueryResponse(
                results=[],
                query_analysis={"error": str(e)},
                personalized_summary="æŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                total_found=0,
                processing_time=processing_time
            )

    async def check_eligibility(self, request: PolicyEligibilityRequest) -> PolicyEligibilityResponse:
        """æ£€æŸ¥æ”¿ç­–èµ„æ ¼ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        start_time = datetime.now()
        
        try:
            # 1. è·å–æ”¿ç­–ä¿¡æ¯ - ä½¿ç”¨ç®€åŒ–æ£€ç´¢
            advanced_request = AdvancedQueryRequest(
                query=f"policy_id:{request.policy_id}",
                strategy=RetrievalStrategy.SIMPLE,
                top_k=20
            )
            
            retrieval_response = await self.retriever.retrieve(advanced_request)
            policy_chunks = retrieval_response.results if retrieval_response.success else []
            
            if not policy_chunks:
                raise ValueError(f"Policy {request.policy_id} not found")
            
            # 2. æå–ç»“æ„åŒ–æ”¿ç­–ä¿¡æ¯
            structured_policy = None
            for chunk in policy_chunks:
                if hasattr(chunk, 'metadata') and 'structured_policy' in chunk.metadata:
                    structured_policy = StructuredPolicy(**chunk.metadata['structured_policy'])
                    break
            
            if not structured_policy:
                # ä¸´æ—¶åˆ›å»ºç»“æ„åŒ–æ”¿ç­–å¯¹è±¡
                full_content = "\n".join([chunk.content for chunk in policy_chunks])
                structured_policy = StructuredPolicy(
                    policy_id=request.policy_id,
                    title="æ”¿ç­–æ ‡é¢˜",
                    full_content=full_content
                )
            
            # 3. å­—æ®µçº§åŒ¹é…åˆ†æ
            field_scores = await self.field_matcher.calculate_field_match_score(
                request.company_info, structured_policy
            )
            
            # 4. è¯¦ç»†æ¡ä»¶åˆ†æ
            detailed_analysis = await self._analyze_detailed_conditions(
                request.company_info, structured_policy
            )
            
            # 5. è®¡ç®—é€šè¿‡ç‡
            pass_rate = self._calculate_enhanced_pass_rate(field_scores, detailed_analysis)
            
            # 6. ç”Ÿæˆç­‰çº§å’Œå»ºè®®
            level = self._determine_level(pass_rate)
            suggestions = await self._generate_enhancement_suggestions(
                request.company_info, structured_policy, detailed_analysis
            )
            
            # 7. é£é™©è¯„ä¼°å’Œæ—¶é—´çº¿
            risk_factors = self._assess_risk_factors(detailed_analysis)
            timeline_estimate = self._estimate_timeline(structured_policy, detailed_analysis)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # è½¬æ¢ä¸ºå…¼å®¹çš„ConditionAnalysisæ ¼å¼
            from models import ConditionAnalysis, RequirementStatus
            
            condition_analysis = ConditionAnalysis(
                satisfied_conditions=[
                    RequirementStatus(
                        condition=cond.condition,
                        status=cond.status,
                        details=cond.description,
                        importance="å¿…è¦æ¡ä»¶" if cond.importance > 0.7 else "åŠ åˆ†é¡¹" if cond.importance > 0.5 else "ä¸€èˆ¬è¦æ±‚"
                    )
                    for cond in detailed_analysis.get('basic_conditions', [])
                    if cond.status == "æ»¡è¶³"
                ],
                pending_conditions=[
                    RequirementStatus(
                        condition=cond.condition,
                        status=cond.status,
                        details=cond.description,
                        importance="å¿…è¦æ¡ä»¶" if cond.importance > 0.7 else "åŠ åˆ†é¡¹" if cond.importance > 0.5 else "ä¸€èˆ¬è¦æ±‚"
                    )
                    for cond in detailed_analysis.get('basic_conditions', [])
                    if cond.status == "å¾…å®Œå–„"
                ],
                unknown_conditions=[
                    RequirementStatus(
                        condition=cond.condition,
                        status=cond.status,
                        details=cond.description,
                        importance="å¿…è¦æ¡ä»¶" if cond.importance > 0.7 else "åŠ åˆ†é¡¹" if cond.importance > 0.5 else "ä¸€èˆ¬è¦æ±‚"
                    )
                    for cond in detailed_analysis.get('basic_conditions', [])
                    if cond.status == "ä¸ç¡®å®š"
                ]
            )
            
            return PolicyEligibilityResponse(
                policy_id=request.policy_id,
                policy_name=structured_policy.title,
                policy_type=structured_policy.tool_category or "æ”¿ç­–æ”¯æŒ",
                support_amount=str(structured_policy.support_amount_range) if structured_policy.support_amount_range else "è¯¦è§æ”¿ç­–æ¡æ–‡",
                pass_rate=int(pass_rate * 100),  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                pass_level=level,
                condition_analysis=condition_analysis,
                suggestions=suggestions,
                processing_time=processing_time,
                
                # å¢å¼ºå­—æ®µ
                policy_info=structured_policy,
                detailed_analysis=detailed_analysis,
                matching_score=sum(field_scores.values()) / len(field_scores),
                feasibility_assessment=self._assess_feasibility(pass_rate, risk_factors),
                timeline_estimate=timeline_estimate,
                risk_factors=risk_factors,
                
                # ğŸ†• æ·»åŠ ç”¨äºæ•°æ®åº“å…³è”çš„å­—æ®µ
                original_filename=getattr(structured_policy, 'original_filename', None),
                file_path=getattr(structured_policy, 'file_path', None),
                document_number=structured_policy.document_number,
                issuing_agency=structured_policy.issuing_agency
            )
            
        except Exception as e:
            logger.error(f"Enhanced eligibility check failed: {str(e)}")
            processing_time = (datetime.now() - start_time).total_seconds()
            from models import ConditionAnalysis
            return PolicyEligibilityResponse(
                policy_id=request.policy_id,
                policy_name="æœªçŸ¥æ”¿ç­–",
                policy_type="æ”¿ç­–æ”¯æŒ",
                support_amount="æœªçŸ¥",
                pass_rate=0,
                pass_level="ä½", 
                condition_analysis=ConditionAnalysis(
                    satisfied_conditions=[],
                    pending_conditions=[],
                    unknown_conditions=[]
                ),
                suggestions=["ç³»ç»Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"],
                processing_time=processing_time
            )

    async def _analyze_detailed_conditions(self, company_info: CompanyInfo, 
                                         policy: StructuredPolicy) -> Dict[str, Any]:
        """è¯¦ç»†åˆ†ææ¡ä»¶åŒ¹é…"""
        analysis = {
            'basic_conditions': [],
            'qualification_conditions': [],
            'material_conditions': [],
            'process_requirements': [],
            'overall_assessment': {}
        }
        
        # åˆ†æåŸºç¡€æ¡ä»¶
        if policy.condition_requirements:
            basic_analysis = await self._analyze_basic_conditions(
                company_info, policy.condition_requirements
            )
            analysis['basic_conditions'] = basic_analysis
        
        # åˆ†ææœåŠ¡å¯¹è±¡åŒ¹é…
        if policy.service_object:
            qualification_analysis = await self._analyze_qualification_match(
                company_info, policy.service_object
            )
            analysis['qualification_conditions'] = qualification_analysis
        
        # åˆ†ææœåŠ¡æµç¨‹è¦æ±‚
        if policy.service_process:
            process_analysis = self._analyze_process_requirements(policy.service_process)
            analysis['process_requirements'] = process_analysis
        
        return analysis

    async def _analyze_basic_conditions(self, company_info: CompanyInfo, 
                                       conditions: str) -> List[EnhancedRequirementStatus]:
        """åˆ†æåŸºç¡€æ¡ä»¶"""
        # ä½¿ç”¨LLMè¿›è¡Œè¯¦ç»†æ¡ä»¶åˆ†æ
        prompt = f"""
        è¯·è¯¦ç»†åˆ†æä¼ä¸šæ˜¯å¦æ»¡è¶³ä»¥ä¸‹æ”¿ç­–æ¡ä»¶ï¼Œå¯¹æ¯ä¸ªæ¡ä»¶ç»™å‡ºçŠ¶æ€è¯„ä¼°ï¼š

        ä¼ä¸šä¿¡æ¯ï¼š
        - å…¬å¸åç§°ï¼š{company_info.company_name}
        - è¡Œä¸šï¼š{company_info.industry}
        - è§„æ¨¡ï¼š{company_info.scale}
        - å‘˜å·¥æ•°ï¼š{company_info.employees}
        - å¹´è¥ä¸šé¢ï¼š{company_info.annual_revenue}

        æ”¿ç­–æ¡ä»¶ï¼š
        {conditions}

        è¯·åˆ†ææ¯ä¸ªå…·ä½“æ¡ä»¶ï¼Œè¿”å›JSONæ ¼å¼ï¼š
        [
            {{
                "condition": "å…·ä½“æ¡ä»¶æè¿°",
                "status": "æ»¡è¶³/å¾…å®Œå–„/ä¸ç¡®å®š",
                "description": "è¯¦ç»†åˆ†æè¯´æ˜",
                "importance": 0.8,
                "improvement_suggestion": "æ”¹è¿›å»ºè®®"
            }}
        ]
        """
        
        try:
            response = await self.llm_manager.generate_policy_analysis(prompt, company_info.__dict__)
            # è§£æJSONå“åº”
            import json
            conditions_list = json.loads(response)
            
            return [
                EnhancedRequirementStatus(
                    condition=item['condition'],
                    status=item['status'],
                    description=item['description'],
                    importance=item.get('importance', 0.5),
                    source_field='condition_requirements',
                    requirement_type='åŸºç¡€æ¡ä»¶',
                    improvement_suggestion=item.get('improvement_suggestion')
                )
                for item in conditions_list
            ]
            
        except Exception as e:
            logger.warning(f"LLM condition analysis failed: {e}")
            return [
                EnhancedRequirementStatus(
                    condition="æ¡ä»¶åˆ†æ",
                    status="ä¸ç¡®å®š",
                    description="æ— æ³•å®Œæˆè¯¦ç»†åˆ†æ",
                    importance=0.5
                )
            ]

    def _calculate_enhanced_pass_rate(self, field_scores: Dict[str, float], 
                                    detailed_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—å¢å¼ºçš„é€šè¿‡ç‡"""
        # åŸºäºå­—æ®µåŒ¹é…åˆ†æ•°
        field_score = sum(
            score * self.field_matcher.field_weights.get(field, 0.1)
            for field, score in field_scores.items()
        )
        
        # åŸºäºè¯¦ç»†æ¡ä»¶åˆ†æ
        condition_score = 0.5
        if detailed_analysis.get('basic_conditions'):
            satisfied_count = sum(
                1 for cond in detailed_analysis['basic_conditions']
                if cond.status == "æ»¡è¶³"
            )
            total_count = len(detailed_analysis['basic_conditions'])
            if total_count > 0:
                condition_score = satisfied_count / total_count
        
        # ç»¼åˆè®¡ç®—
        pass_rate = 0.6 * field_score + 0.4 * condition_score
        return round(pass_rate, 3)

    def _determine_level(self, pass_rate: float) -> str:
        """ç¡®å®šèµ„æ ¼ç­‰çº§"""
        if pass_rate >= 0.8:
            return "é«˜"
        elif pass_rate >= 0.6:
            return "ä¸­"
        else:
            return "ä½"

    async def _generate_enhancement_suggestions(self, company_info: CompanyInfo,
                                              policy: StructuredPolicy,
                                              analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # åŸºäºå­—æ®µåˆ†æçš„å»ºè®®
        if policy.condition_requirements:
            suggestions.append(f"é‡ç‚¹å…³æ³¨æ”¿ç­–æ¡ä»¶è¦æ±‚ï¼š{policy.condition_requirements[:100]}...")
        
        if policy.service_process:
            suggestions.append(f"äº†è§£ç”³è¯·æµç¨‹ï¼š{policy.service_process[:100]}...")
        
        if policy.contact_info:
            suggestions.append(f"åŠæ—¶è”ç³»å’¨è¯¢ï¼š{policy.contact_info}")
        
        # åŸºäºæ¡ä»¶åˆ†æçš„å»ºè®®
        for condition in analysis.get('basic_conditions', []):
            if condition.status == "å¾…å®Œå–„" and condition.improvement_suggestion:
                suggestions.append(condition.improvement_suggestion)
        
        return suggestions

    def _assess_risk_factors(self, analysis: Dict[str, Any]) -> List[str]:
        """è¯„ä¼°é£é™©å› ç´ """
        risks = []
        
        for condition in analysis.get('basic_conditions', []):
            if condition.status == "å¾…å®Œå–„" and condition.importance > 0.7:
                risks.append(f"é«˜é‡è¦æ€§æ¡ä»¶å¾…å®Œå–„ï¼š{condition.condition}")
        
        return risks

    def _estimate_timeline(self, policy: StructuredPolicy, 
                          analysis: Dict[str, Any]) -> str:
        """ä¼°è®¡æ—¶é—´çº¿"""
        if policy.time_frequency:
            if 'å¸¸å¹´' in policy.time_frequency:
                return "å¯éšæ—¶ç”³è¯·ï¼Œå»ºè®®å°½å¿«å‡†å¤‡ææ–™"
            elif 'æ‰¹æ¬¡' in policy.time_frequency:
                return "æŒ‰æ‰¹æ¬¡å—ç†ï¼Œéœ€å…³æ³¨ç”³è¯·æ—¶é—´çª—å£"
        
        return "å»ºè®®æå‰3-6ä¸ªæœˆå‡†å¤‡ç”³è¯·ææ–™"

    def _assess_feasibility(self, pass_rate: float, risk_factors: List[str]) -> str:
        """è¯„ä¼°å¯è¡Œæ€§"""
        if pass_rate >= 0.8 and len(risk_factors) == 0:
            return "å¯è¡Œæ€§é«˜ï¼Œå»ºè®®ç«‹å³ç”³è¯·"
        elif pass_rate >= 0.6:
            return "å¯è¡Œæ€§ä¸­ç­‰ï¼Œéœ€è¦å®Œå–„éƒ¨åˆ†æ¡ä»¶"
        else:
            return "å¯è¡Œæ€§è¾ƒä½ï¼Œéœ€è¦æ˜¾è‘—æ”¹å–„æ¡ä»¶"
    
    def _extract_policy_name(self, result) -> str:
        """ä»æ£€ç´¢ç»“æœä¸­æå–æ”¿ç­–åç§°"""
        # å°è¯•ä»å†…å®¹ä¸­æå–æ ‡é¢˜
        content = result.content
        lines = content.split('\n')
        for line in lines[:5]:  # æ£€æŸ¥å‰5è¡Œ
            line = line.strip()
            if len(line) > 10 and not line.startswith(('ç¬¬', 'ä¸€ã€', 'äºŒã€', 'ä¸‰ã€', 'ï¼ˆ')):
                return line
        # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„æ ‡é¢˜ï¼Œä½¿ç”¨æ”¿ç­–ID
        return f"æ”¿ç­–æ–‡æ¡£ {result.policy_id}"
    
    def _infer_policy_type(self, content: str) -> str:
        """ä»å†…å®¹æ¨æ–­æ”¿ç­–ç±»å‹"""
        content_lower = content.lower()
        if any(keyword in content_lower for keyword in ['èµ„é‡‘', 'è¡¥åŠ©', 'è¡¥è´´', 'æ‰¶æŒ']):
            return "èµ„é‡‘æ”¯æŒ"
        elif any(keyword in content_lower for keyword in ['è®¤å®š', 'èµ„è´¨', 'é«˜æ–°', 'ä¸“ç²¾ç‰¹æ–°']):
            return "èµ„è´¨è®¤å®š"
        elif any(keyword in content_lower for keyword in ['äººæ‰', 'è½æˆ·', 'ä½æˆ¿']):
            return "äººæ‰æ”¯æŒ"
        elif any(keyword in content_lower for keyword in ['ç¨æ”¶', 'å‡å…', 'ä¼˜æƒ ']):
            return "ç¨æ”¶ä¼˜æƒ "
        elif any(keyword in content_lower for keyword in ['ç©ºé—´', 'ç§Ÿé‡‘', 'å®éªŒå®¤']):
            return "ç©ºé—´æ”¯æŒ"
        else:
            return "æ”¿ç­–æ”¯æŒ"
    
    def _extract_support_content(self, content: str) -> str:
        """æå–æ”¯æŒå†…å®¹"""
        # å¯»æ‰¾åŒ…å«æ”¯æŒå†…å®¹çš„æ®µè½
        sentences = content.split('ã€‚')
        for sentence in sentences:
            if any(keyword in sentence for keyword in ['æ”¯æŒ', 'è¡¥åŠ©', 'è¡¥è´´', 'æ‰¶æŒ', 'èµ„åŠ©']):
                return sentence.strip()[:100] + "..."
        return "è¯¦è§æ”¿ç­–æ¡æ–‡"
    
    def _extract_conditions(self, content: str) -> str:
        """æå–ç”³è¯·æ¡ä»¶"""
        sentences = content.split('ã€‚')
        for sentence in sentences:
            if any(keyword in sentence for keyword in ['æ¡ä»¶', 'è¦æ±‚', 'åº”å½“', 'å¿…é¡»', 'éœ€è¦']):
                return sentence.strip()[:100] + "..."
        return "è¯¦è§æ”¿ç­–æ¡æ–‡"
    
    def _simple_vector_search(self, request) -> List:
        """ç®€å•çš„åŒæ­¥å‘é‡æœç´¢"""
        from vector_store import VectorStore
        from embeddings import EmbeddingManager
        from models import RetrievalResult
        
        try:
            # åˆå§‹åŒ–ç»„ä»¶
            vector_store = VectorStore()
            embedding_manager = EmbeddingManager()
            
            if not vector_store.milvus.connected:
                return []
            
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = embedding_manager.encode_texts([request.query])
            
            # æ‰§è¡Œæœç´¢
            results = vector_store.milvus.search(query_embedding[0], top_k=request.top_k or 10)
            
            # è½¬æ¢ä¸ºRetrievalResultæ ¼å¼
            retrieval_results = []
            for result in results:
                retrieval_results.append(RetrievalResult(
                    chunk_id=result.chunk_id,
                    content=result.content,
                    score=float(result.score),
                    policy_id=result.policy_id,
                    metadata=result.metadata or {}
                ))
                
            return retrieval_results
            
        except Exception as e:
            logger.error(f"ç®€å•å‘é‡æœç´¢å¤±è´¥: {e}")
            return []
    
    def basic_match(self, request: 'BasicMatchRequest') -> 'OneClickMatchResponse':
        """åŸºç¡€åŒ¹é…åŠŸèƒ½ - ä½¿ç”¨çœŸå®å‘é‡æ£€ç´¢"""
        start_time = datetime.now()
        
        try:
            from models import PolicyMatch, OneClickMatchResponse, QueryRequest
            
            # ğŸ†• æ„å»ºæŸ¥è¯¢æ–‡æœ¬ï¼ŒåŸºäºç”¨æˆ·é€‰æ‹©çš„æ¡ä»¶
            query_parts = []
            if request.industry:
                query_parts.append(request.industry)
            if request.demand_type:
                if "èµ„é‡‘" in request.demand_type:
                    query_parts.append("èµ„é‡‘æ”¯æŒ è¡¥åŠ© æ‰¶æŒ")
                elif "èµ„è´¨" in request.demand_type:
                    query_parts.append("èµ„è´¨è®¤å®š é«˜æ–°ä¼ä¸š ä¸“ç²¾ç‰¹æ–°")
                elif "äººæ‰" in request.demand_type:
                    query_parts.append("äººæ‰æ”¯æŒ è½æˆ· ä½æˆ¿è¡¥è´´")
                elif "ç©ºé—´" in request.demand_type:
                    query_parts.append("ç©ºé—´æ”¯æŒ å®éªŒå®¤ ç§Ÿé‡‘å‡å…")
            
            # ä¼ä¸šè§„æ¨¡ç›¸å…³å…³é”®è¯
            if "åˆåˆ›" in request.company_scale:
                query_parts.append("åˆåˆ›ä¼ä¸š å°å¾®ä¼ä¸š")
            elif "ä¸­å°" in request.company_scale:
                query_parts.append("ä¸­å°ä¼ä¸š")
            elif "å¤§å‹" in request.company_scale:
                query_parts.append("å¤§å‹ä¼ä¸š")
            
            query_text = " ".join(query_parts) if query_parts else f"{request.industry} {request.demand_type}"
            
            # ğŸ†• ä½¿ç”¨å‘é‡æ£€ç´¢æ›¿ä»£æ¨¡æ‹Ÿæ•°æ®
            query_request = QueryRequest(
                query=query_text,
                industry=request.industry,
                enterprise_scale=request.company_scale,
                top_k=10
            )
            
            # è°ƒç”¨çœŸå®çš„æŸ¥è¯¢ç³»ç»Ÿ
            query_response = self.match_policies(query_request)
            
            # å°†æ£€ç´¢ç»“æœè½¬æ¢ä¸ºPolicyMatchæ ¼å¼
            matches = []
            for result in query_response.results[:10]:
                # ä»å‘é‡æ£€ç´¢ç»“æœä¸­æå–æ”¿ç­–ä¿¡æ¯
                policy_name = self._extract_policy_name(result)
                match_score = min(result.score * 1.2, 1.0)  # è°ƒæ•´åˆ†æ•°èŒƒå›´
                
                matches.append(PolicyMatch(
                    policy_id=result.policy_id,
                    policy_name=policy_name,
                    match_score=round(match_score, 2),
                    match_level="é«˜" if match_score >= 0.8 else "ä¸­" if match_score >= 0.6 else "ä½",
                    key_description=result.content[:150] + "...",
                    policy_type=self._infer_policy_type(result.content),
                    support_content=self._extract_support_content(result.content),
                    application_conditions=self._extract_conditions(result.content),
                    # ä½¿ç”¨çœŸå®çš„å…³è”å­—æ®µ
                    original_filename=getattr(result, 'original_filename', None),
                    file_path=getattr(result, 'file_path', None),
                    document_number=getattr(result, 'document_number', None),
                    issuing_agency=getattr(result, 'issuing_agency', None)
                ))
            
            # å¦‚æœå‘é‡æ£€ç´¢æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨å¤‡ç”¨æ¨¡æ‹Ÿæ•°æ®
            if not matches:
                logger.warning("å‘é‡æ£€ç´¢æ— ç»“æœï¼Œä½¿ç”¨å¤‡ç”¨æ¨¡æ‹Ÿæ•°æ®")
                # ä¿ç•™åŸæœ‰çš„æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå¤‡ç”¨
                mock_policies = [
                {
                    "policy_id": "policy_001",
                    "policy_name": "ç”Ÿç‰©åŒ»è¯äº§ä¸šå‘å±•æ”¯æŒæ”¿ç­–",
                    "match_score": 0.85,
                    "match_level": "é«˜",
                    "key_description": "æ”¯æŒç”Ÿç‰©åŒ»è¯ä¼ä¸šç ”å‘åˆ›æ–°ï¼Œæä¾›æœ€é«˜500ä¸‡å…ƒèµ„é‡‘æ”¯æŒï¼Œé€‚åˆåˆåˆ›ä¼ä¸šç”³è¯·",
                    "policy_type": "èµ„é‡‘æ”¯æŒ",
                    "support_content": "ç ”å‘è´¹ç”¨è¡¥åŠ©ã€è®¾å¤‡è´­ç½®æ”¯æŒ",
                    "application_conditions": "æ³¨å†Œåœ¨ä¸­å…³æ‘ç¤ºèŒƒåŒºï¼Œæˆç«‹ä¸è¶…è¿‡3å¹´",
                    # ğŸ†• æ·»åŠ ç”¨äºæ•°æ®åº“å…³è”çš„å­—æ®µ
                    "original_filename": "ç”Ÿç‰©åŒ»è¯äº§ä¸šå‘å±•æ”¯æŒæ”¿ç­–.pdf",
                    "file_path": "/policies/ç”Ÿç‰©åŒ»è¯äº§ä¸šå‘å±•æ”¯æŒæ”¿ç­–.pdf",
                    "document_number": "äº¬å‘æ”¹ã€”2023ã€•15å·",
                    "issuing_agency": "åŒ—äº¬å¸‚å‘å±•å’Œæ”¹é©å§”å‘˜ä¼š"
                },
                {
                    "policy_id": "policy_002", 
                    "policy_name": "åˆåˆ›ä¼ä¸šå­µåŒ–å™¨æ”¯æŒè®¡åˆ’",
                    "match_score": 0.78,
                    "match_level": "é«˜",
                    "key_description": "ä¸ºåˆåˆ›ä¼ä¸šæä¾›å­µåŒ–ç©ºé—´å’Œåˆ›ä¸šè¾…å¯¼ï¼Œå‡å…ç§Ÿé‡‘æœ€é«˜80%ï¼Œæä¾›ä¸“ä¸šæœåŠ¡",
                    "policy_type": "ç©ºé—´æ”¯æŒ",
                    "support_content": "å­µåŒ–ç©ºé—´ã€åˆ›ä¸šè¾…å¯¼ã€èµ„æºå¯¹æ¥",
                    "application_conditions": "æˆç«‹ä¸è¶…è¿‡3å¹´ï¼Œå‘˜å·¥å°‘äº20äºº",
                    # ğŸ†• æ·»åŠ ç”¨äºæ•°æ®åº“å…³è”çš„å­—æ®µ
                    "original_filename": "åˆåˆ›ä¼ä¸šå­µåŒ–å™¨æ”¯æŒè®¡åˆ’.pdf",
                    "file_path": "/policies/åˆåˆ›ä¼ä¸šå­µåŒ–å™¨æ”¯æŒè®¡åˆ’.pdf",
                    "document_number": "äº¬ç§‘å‘ã€”2023ã€•8å·",
                    "issuing_agency": "åŒ—äº¬å¸‚ç§‘å­¦æŠ€æœ¯å§”å‘˜ä¼š"
                },
                {
                    "policy_id": "policy_003",
                    "policy_name": "ä¼ä¸šç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æ”¿ç­–",
                    "match_score": 0.72,
                    "match_level": "ä¸­",
                    "key_description": "ç ”å‘è´¹ç”¨å¯äº«å—175%åŠ è®¡æ‰£é™¤ï¼Œæœ‰æ•ˆé™ä½ä¼ä¸šç¨è´Ÿï¼Œé€‚åˆæœ‰ç ”å‘æŠ•å…¥çš„ä¼ä¸š",
                    "policy_type": "ç¨æ”¶ä¼˜æƒ ",
                    "support_content": "ç ”å‘è´¹ç”¨ç¨å‰åŠ è®¡æ‰£é™¤",
                    "application_conditions": "æœ‰ç ”å‘æ´»åŠ¨å’Œè´¹ç”¨æ”¯å‡ºè®°å½•",
                    # ğŸ†• æ·»åŠ ç”¨äºæ•°æ®åº“å…³è”çš„å­—æ®µ
                    "original_filename": "ä¼ä¸šç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æ”¿ç­–.docx",
                    "file_path": "/policies/ä¼ä¸šç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æ”¿ç­–.docx",
                    "document_number": "è´¢ç¨ã€”2023ã€•28å·",
                    "issuing_agency": "è´¢æ”¿éƒ¨ã€ç¨åŠ¡æ€»å±€"
                }
            ]
            
                # æ ¹æ®è¯·æ±‚å‚æ•°è¿‡æ»¤å’Œè¯„åˆ†ï¼ˆä»…ç”¨äºå¤‡ç”¨æƒ…å†µï¼‰
                for policy in mock_policies:
                    # è¡Œä¸šåŒ¹é…
                    industry_match = self._match_industry(request.industry, policy)
                    # ä¼ä¸šè§„æ¨¡åŒ¹é…
                    scale_match = self._match_scale(request.company_scale, policy)
                    # éœ€æ±‚ç±»å‹åŒ¹é…
                    demand_match = self._match_demand_type(request.demand_type, policy)
                    
                    # ç»¼åˆè¯„åˆ†
                    total_score = (industry_match * 0.4 + scale_match * 0.3 + demand_match * 0.3)
                    
                    if total_score >= 0.5:  # åŒ¹é…é˜ˆå€¼
                        match_level = "é«˜" if total_score >= 0.8 else "ä¸­" if total_score >= 0.6 else "ä½"
                        
                        matches.append(PolicyMatch(
                            policy_id=policy["policy_id"],
                            policy_name=policy["policy_name"],
                            match_score=round(total_score, 2),
                            match_level=match_level,
                            key_description=policy["key_description"],
                            policy_type=policy["policy_type"],
                            support_content=policy["support_content"],
                            application_conditions=policy["application_conditions"],
                            # ğŸ†• æ·»åŠ ç”¨äºæ•°æ®åº“å…³è”çš„å­—æ®µ
                            original_filename=policy.get("original_filename"),
                            file_path=policy.get("file_path"),
                            document_number=policy.get("document_number"),
                            issuing_agency=policy.get("issuing_agency")
                        ))
            
            # æŒ‰åŒ¹é…åˆ†æ•°æ’åºï¼ˆé€‚ç”¨äºæ‰€æœ‰æƒ…å†µï¼‰
            matches.sort(key=lambda x: x.match_score, reverse=True)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return OneClickMatchResponse(
                total_results=len(matches),
                matches=matches,
                processing_time=processing_time,
                match_type="basic",
                suggestions=[
                    "å»ºè®®ä½¿ç”¨ç²¾å‡†åŒ¹é…åŠŸèƒ½è·å¾—æ›´å‡†ç¡®çš„ç»“æœ",
                    "å¯ä»¥ä¸Šä¼ ä¼ä¸šèµ„æ–™è¿›è¡Œè¯¦ç»†åˆ†æ",
                    "å…³æ³¨æ”¿ç­–ç”³è¯·æ—¶é—´çª—å£"
                ]
            )
            
        except Exception as e:
            logger.error(f"åŸºç¡€åŒ¹é…å¤±è´¥: {e}")
            from models import OneClickMatchResponse
            processing_time = (datetime.now() - start_time).total_seconds()
            return OneClickMatchResponse(
                total_results=0,
                matches=[],
                processing_time=processing_time,
                match_type="basic",
                suggestions=[f"åŒ¹é…è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}"]
            )
    
    def precise_match(self, request: 'PreciseMatchRequest') -> 'OneClickMatchResponse':
        """ç²¾å‡†åŒ¹é…åŠŸèƒ½"""
        start_time = datetime.now()
        
        try:
            from models import PolicyMatch, OneClickMatchResponse
            
            # é¦–å…ˆæ‰§è¡ŒåŸºç¡€åŒ¹é…
            basic_response = self.basic_match(request.basic_request)
            
            # åŸºäºä¼ä¸šè¯¦ç»†ä¿¡æ¯è¿›è¡Œç²¾å‡†åŒ¹é…å’Œé‡æ’åº
            enhanced_matches = []
            
            for match in basic_response.matches:
                # ä¼ä¸šä¿¡æ¯åŒ¹é…åº¦åˆ†æ
                company_score = self._analyze_company_match(request.company_info, match)
                
                # é‡æ–°è®¡ç®—åŒ¹é…åˆ†æ•°
                enhanced_score = (match.match_score * 0.6 + company_score * 0.4)
                
                # ç”Ÿæˆæ›´è¯¦ç»†çš„æè¿°
                enhanced_description = self._generate_enhanced_description(
                    request.company_info, match
                )
                
                enhanced_matches.append(PolicyMatch(
                    policy_id=match.policy_id,
                    policy_name=match.policy_name,
                    match_score=round(enhanced_score, 2),
                    match_level="é«˜" if enhanced_score >= 0.8 else "ä¸­" if enhanced_score >= 0.6 else "ä½",
                    key_description=enhanced_description,
                    policy_type=match.policy_type,
                    support_content=match.support_content,
                    application_conditions=match.application_conditions,
                    # ğŸ†• ä¿ç•™åŸæœ‰çš„å…³è”å­—æ®µ
                    original_filename=match.original_filename,
                    file_path=match.file_path,
                    document_number=match.document_number,
                    issuing_agency=match.issuing_agency
                ))
            
            # é‡æ–°æ’åº
            enhanced_matches.sort(key=lambda x: x.match_score, reverse=True)
            
            # ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
            suggestions = self._generate_personalized_suggestions(request.company_info)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return OneClickMatchResponse(
                total_results=len(enhanced_matches),
                matches=enhanced_matches,
                processing_time=processing_time,
                match_type="precise",
                suggestions=suggestions
            )
            
        except Exception as e:
            logger.error(f"ç²¾å‡†åŒ¹é…å¤±è´¥: {e}")
            from models import OneClickMatchResponse
            processing_time = (datetime.now() - start_time).total_seconds()
            return OneClickMatchResponse(
                total_results=0,
                matches=[],
                processing_time=processing_time,
                match_type="precise",
                suggestions=[f"åŒ¹é…è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}"]
            )
    
    def _match_industry(self, requested_industry: str, policy: dict) -> float:
        """è¡Œä¸šåŒ¹é…åº¦è®¡ç®—"""
        # ç®€åŒ–çš„è¡Œä¸šåŒ¹é…é€»è¾‘
        if "ç”Ÿç‰©åŒ»è¯" in requested_industry:
            if "ç”Ÿç‰©åŒ»è¯" in policy["policy_name"] or "åŒ»è¯" in policy["key_description"]:
                return 1.0
            elif "ç ”å‘" in policy["key_description"] or "åˆ›æ–°" in policy["key_description"]:
                return 0.8
        elif "ä¿¡æ¯æŠ€æœ¯" in requested_industry:
            if "ç§‘æŠ€" in policy["policy_name"] or "æŠ€æœ¯" in policy["key_description"]:
                return 1.0
        
        # é»˜è®¤åŒ¹é…åº¦
        return 0.6
    
    def _match_scale(self, requested_scale: str, policy: dict) -> float:
        """ä¼ä¸šè§„æ¨¡åŒ¹é…åº¦è®¡ç®—"""
        if "åˆåˆ›" in requested_scale:
            if "åˆåˆ›" in policy["application_conditions"] or "3å¹´" in policy["application_conditions"]:
                return 1.0
            elif "å­µåŒ–" in policy["policy_name"]:
                return 0.9
        elif "ä¸­å°ä¼ä¸š" in requested_scale:
            if "ä¸­å°" in policy["application_conditions"]:
                return 1.0 
        
        return 0.7
    
    def _match_demand_type(self, requested_demand: str, policy: dict) -> float:
        """éœ€æ±‚ç±»å‹åŒ¹é…åº¦è®¡ç®—"""
        if "èµ„é‡‘" in requested_demand:
            if policy["policy_type"] == "èµ„é‡‘æ”¯æŒ":
                return 1.0
            elif "è´¹ç”¨" in policy["support_content"]:
                return 0.8
        elif "èµ„è´¨" in requested_demand:
            if "è®¤å®š" in policy["policy_name"] or "èµ„è´¨" in policy["policy_type"]:
                return 1.0
        elif "ç©ºé—´" in requested_demand:
            if policy["policy_type"] == "ç©ºé—´æ”¯æŒ":
                return 1.0
        
        return 0.5
    
    def _analyze_company_match(self, company_info: 'CompanyInfo', match: 'PolicyMatch') -> float:
        """åˆ†æä¼ä¸šä¿¡æ¯åŒ¹é…åº¦"""
        score = 0.7  # åŸºç¡€åˆ†æ•°
        
        # æ³¨å†Œèµ„æœ¬åŒ¹é…
        if hasattr(company_info, 'registered_capital') and company_info.registered_capital:
            if company_info.registered_capital <= 1000:  # å°ä¼ä¸š
                if "åˆåˆ›" in match.application_conditions or "å°å‹" in match.application_conditions:
                    score += 0.1
            else:  # å¤§ä¼ä¸š
                if "å¤§å‹" in match.application_conditions:
                    score += 0.1
        
        # å‘˜å·¥æ•°åŒ¹é…
        if hasattr(company_info, 'employees') and company_info.employees:
            if company_info.employees < 20:
                if "20äºº" in match.application_conditions:
                    score += 0.1
            elif company_info.employees < 200:
                if "ä¸­å°" in match.application_conditions:
                    score += 0.1
        
        # å¹´è¥ä¸šé¢åŒ¹é…
        if hasattr(company_info, 'annual_revenue') and company_info.annual_revenue:
            if company_info.annual_revenue < 1000:  # å°ä¼ä¸š
                if "åˆåˆ›" in match.application_conditions:
                    score += 0.1
        
        return min(score, 1.0)
    
    def _generate_enhanced_description(self, company_info: 'CompanyInfo', match: 'PolicyMatch') -> str:
        """ç”Ÿæˆå¢å¼ºçš„æ”¿ç­–æè¿°"""
        base_description = match.key_description or ""
        
        # æ·»åŠ ä¼ä¸šç›¸å…³çš„ä¸ªæ€§åŒ–ä¿¡æ¯
        if hasattr(company_info, 'company_name') and company_info.company_name:
            scale = getattr(company_info, 'scale', None)
            employees = getattr(company_info, 'employees', None)
            
            if scale and "åˆåˆ›" in scale or (employees and employees < 20):
                enhanced = f"ç‰¹åˆ«é€‚åˆ{company_info.company_name}ç­‰åˆåˆ›ä¼ä¸šï¼Œ{base_description}"
            else:
                enhanced = f"é€‚åˆ{company_info.company_name}ç”³è¯·ï¼Œ{base_description}"
        else:
            enhanced = base_description
        
        return enhanced[:150]  # é™åˆ¶150å­—ç¬¦
    
    def _generate_personalized_suggestions(self, company_info: 'CompanyInfo') -> List[str]:
        """ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®"""
        suggestions = []
        
        if hasattr(company_info, 'registered_capital') and company_info.registered_capital and company_info.registered_capital <= 500:
            suggestions.append("ä½œä¸ºå°è§„æ¨¡ä¼ä¸šï¼Œé‡ç‚¹å…³æ³¨åˆåˆ›ä¼ä¸šä¸“é¡¹æ”¿ç­–")
        
        if hasattr(company_info, 'employees') and company_info.employees and company_info.employees < 20:
            suggestions.append("å¯ç”³è¯·å­µåŒ–å™¨å…¥é©»ï¼Œäº«å—åœºåœ°å’ŒæœåŠ¡æ”¯æŒ")
        
        if hasattr(company_info, 'annual_revenue') and company_info.annual_revenue and company_info.annual_revenue < 1000:
            suggestions.append("ä¼˜å…ˆç”³è¯·èµ„é‡‘æ”¯æŒç±»æ”¿ç­–ï¼Œé™ä½è¿è¥æˆæœ¬")
        
        if not suggestions:
            suggestions.append("å»ºè®®å®Œå–„ä¼ä¸šèµ„æ–™ä»¥è·å¾—æ›´ç²¾å‡†çš„æ”¿ç­–æ¨è")
        
        suggestions.append("åŠæ—¶å…³æ³¨æ”¿ç­–ç”³è¯·æˆªæ­¢æ—¶é—´")
        suggestions.append("å‡†å¤‡é½å…¨ç”³è¯·ææ–™ï¼Œæé«˜ç”³è¯·æˆåŠŸç‡")
        
        return suggestions
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            status = {
                "status": "è¿è¡Œä¸­",
                "vector_store": {
                    "milvus_connected": True,
                    "elasticsearch_connected": True,
                    "milvus_stats": {
                        "row_count": 1000  # æ¨¡æ‹Ÿæ•°æ®
                    }
                },
                "embedding_model": {
                    "status": "loaded",
                    "model_name": "moka-ai/m3e-base"
                },
                "llm_manager": {
                    "status": "ready",
                    "model": "deepseek-chat"
                }
            }
            return status
        except Exception as e:
            logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {
                "status": "é”™è¯¯",
                "error": str(e),
                "vector_store": {
                    "milvus_connected": False,
                    "elasticsearch_connected": False
                },
                "embedding_model": {
                    "status": "error"
                }
            }
    
    def add_policy_document(self, file_path: str) -> bool:
        """æ·»åŠ æ”¿ç­–æ–‡æ¡£"""
        try:
            logger.info(f"å¼€å§‹æ·»åŠ æ”¿ç­–æ–‡æ¡£: {file_path}")
            
            # 1. ä½¿ç”¨DocumentProcessorå¤„ç†æ–‡æ¡£
            from document_processor import DocumentProcessor
            processor = DocumentProcessor(self.config)
            
            # å¤„ç†æ–‡æ¡£ï¼Œè·å–PolicyDocumentå¯¹è±¡
            policy_doc = processor.process_document(file_path)
            
            # 2. ç”Ÿæˆå‘é‡åµŒå…¥
            from embeddings import EmbeddingManager
            embedding_model = EmbeddingManager()
            
            # æå–æ‰€æœ‰åˆ†å—çš„æ–‡æœ¬å†…å®¹
            chunk_texts = [chunk.content for chunk in policy_doc.chunks]
            if not chunk_texts:
                logger.warning(f"æ–‡æ¡£æ²¡æœ‰ç”Ÿæˆåˆ†å—: {file_path}")
                return False
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            embeddings = embedding_model.encode_texts(chunk_texts)
            logger.info(f"å‘é‡ç¼–ç å®Œæˆï¼Œå½¢çŠ¶: {embeddings.shape}")
            
            # 3. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            from vector_store import VectorStore
            vector_store = VectorStore()
            
            # å‡†å¤‡å…ƒæ•°æ®
            policy_metadata = {
                'industries': policy_doc.industry if isinstance(policy_doc.industry, list) else [policy_doc.industry] if policy_doc.industry else [],
                'enterprise_scales': policy_doc.enterprise_scale if isinstance(policy_doc.enterprise_scale, list) else [policy_doc.enterprise_scale] if policy_doc.enterprise_scale else [],
                'policy_types': [policy_doc.policy_type] if policy_doc.policy_type else []
            }
            
            # å­˜å‚¨åˆ†å—å’ŒåµŒå…¥
            success = vector_store.store_policy_chunks(
                chunks=policy_doc.chunks,
                embeddings=embeddings,
                policy_title=policy_doc.title,
                policy_metadata=policy_metadata
            )
            
            if success:
                logger.info(f"æ”¿ç­–æ–‡æ¡£å­˜å‚¨æˆåŠŸ: {file_path}")
                return True
            else:
                logger.error(f"æ”¿ç­–æ–‡æ¡£å­˜å‚¨å¤±è´¥: {file_path}")
                return False
                
        except Exception as e:
            logger.error(f"æ·»åŠ æ”¿ç­–æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def analyze_policy_eligibility(self, request) -> 'PolicyEligibilityResponse':
        """æ”¿ç­–èµ„æ ¼åˆ†ææ–¹æ³•"""
        try:
            from models import PolicyEligibilityResponse, ConditionAnalysis, RequirementStatus
            
            # æ¨¡æ‹Ÿæ”¿ç­–èµ„æ ¼åˆ†æ
            company_info = request.company_info
            policy_id = request.policy_id
            
            logger.info(f"å¼€å§‹åˆ†ææ”¿ç­–èµ„æ ¼: æ”¿ç­–ID={policy_id}, ä¼ä¸š={company_info.company_name}")
            
            # åŸºç¡€åŒ¹é…åˆ†æ
            base_score = 0.7  # åŸºç¡€åˆ†æ•°
            
            # ä¼ä¸šè§„æ¨¡è¯„ä¼°
            if hasattr(company_info, 'registered_capital') and company_info.registered_capital:
                if company_info.registered_capital <= 1000:  # å°ä¼ä¸šæ›´å®¹æ˜“è·å¾—æ”¯æŒ
                    base_score += 0.1
            
            # è¡Œä¸šåŒ¹é…è¯„ä¼°
            if hasattr(company_info, 'business_scope') and company_info.business_scope:
                if any(keyword in company_info.business_scope for keyword in ['æŠ€æœ¯', 'ç ”å‘', 'åˆ›æ–°', 'ç§‘æŠ€']):
                    base_score += 0.1
            
            # æˆç«‹æ—¶é—´è¯„ä¼°
            if hasattr(company_info, 'establishment_date') and company_info.establishment_date:
                # åˆåˆ›ä¼ä¸šï¼ˆæˆç«‹3å¹´å†…ï¼‰æ›´å®¹æ˜“è·å¾—æ”¯æŒ
                base_score += 0.05
            
            # è®¡ç®—é€šè¿‡ç‡
            pass_rate = min(int(base_score * 100), 95)  # æœ€é«˜95%
            
            # ç¡®å®šç­‰çº§
            if pass_rate >= 80:
                pass_level = "é«˜"
            elif pass_rate >= 60:
                pass_level = "ä¸­"
            else:
                pass_level = "ä½"
            
            # æ„å»ºæ¡ä»¶åˆ†æ
            satisfied_conditions = []
            pending_conditions = []
            unknown_conditions = []
            
            # æ»¡è¶³çš„æ¡ä»¶
            if company_info.company_name:
                satisfied_conditions.append(RequirementStatus(
                    condition="ä¼ä¸šå·²ä¾æ³•æ³¨å†Œæˆç«‹",
                    status="æ»¡è¶³",
                    details=f"ä¼ä¸šåç§°ï¼š{company_info.company_name}",
                    importance="å¿…è¦æ¡ä»¶"
                ))
            
            if hasattr(company_info, 'business_scope') and company_info.business_scope:
                satisfied_conditions.append(RequirementStatus(
                    condition="ç»è¥èŒƒå›´ç¬¦åˆæ”¿ç­–è¦æ±‚",
                    status="æ»¡è¶³", 
                    details="ä¸šåŠ¡èŒƒå›´åŒ…å«æŠ€æœ¯ç ”å‘ç›¸å…³å†…å®¹",
                    importance="å¿…è¦æ¡ä»¶"
                ))
            
            # å¾…å®Œå–„çš„æ¡ä»¶
            if not hasattr(company_info, 'annual_revenue') or not company_info.annual_revenue:
                pending_conditions.append(RequirementStatus(
                    condition="æä¾›è¿‘ä¸‰å¹´è´¢åŠ¡æŠ¥è¡¨",
                    status="å¾…å®Œå–„",
                    details="éœ€è¦æä¾›è¯¦ç»†çš„è´¢åŠ¡æ•°æ®ä»¥è¿›è¡Œå‡†ç¡®è¯„ä¼°",
                    importance="é‡è¦æ¡ä»¶"
                ))
            
            # ä¸ç¡®å®šçš„æ¡ä»¶
            unknown_conditions.append(RequirementStatus(
                condition="çŸ¥è¯†äº§æƒæƒ…å†µ",
                status="ä¸ç¡®å®š",
                details="éœ€è¦äº†è§£ä¼ä¸šä¸“åˆ©ã€å•†æ ‡ç­‰çŸ¥è¯†äº§æƒçŠ¶å†µ",
                importance="åŠ åˆ†é¡¹"
            ))
            
            condition_analysis = ConditionAnalysis(
                satisfied_conditions=satisfied_conditions,
                pending_conditions=pending_conditions,
                unknown_conditions=unknown_conditions
            )
            
            # ç”Ÿæˆå»ºè®®
            suggestions = []
            if pass_rate < 70:
                suggestions.append("å»ºè®®å®Œå–„ä¼ä¸šèµ„è´¨è¯æ˜ææ–™")
                suggestions.append("å¯è€ƒè™‘å…ˆç”³è¯·å…¶ä»–é—¨æ§›è¾ƒä½çš„æ”¿ç­–")
            else:
                suggestions.append("ä¼ä¸šæ¡ä»¶è¾ƒå¥½ï¼Œå»ºè®®å°½å¿«å‡†å¤‡ç”³è¯·ææ–™")
                suggestions.append("å…³æ³¨æ”¿ç­–ç”³è¯·æˆªæ­¢æ—¶é—´ï¼ŒåŠæ—¶æäº¤ç”³è¯·")
            
            suggestions.append("å»ºè®®å’¨è¯¢ä¸“ä¸šæœåŠ¡æœºæ„è·å¾—ç”³è¯·æŒ‡å¯¼")
            
            return PolicyEligibilityResponse(
                policy_id=policy_id,
                policy_name="åŒ—äº¬å¸‚äº§ä¸šæ”¿ç­–æ”¯æŒè®¡åˆ’",
                policy_type="èµ„é‡‘æ”¯æŒ",
                support_amount="æœ€é«˜500ä¸‡å…ƒ",
                pass_rate=pass_rate,
                pass_level=pass_level,
                condition_analysis=condition_analysis,
                suggestions=suggestions,
                processing_time=0.1
            )
            
        except Exception as e:
            logger.error(f"æ”¿ç­–èµ„æ ¼åˆ†æå¤±è´¥: {e}")
            # è¿”å›é”™è¯¯æƒ…å†µä¸‹çš„é»˜è®¤å“åº”
            from models import PolicyEligibilityResponse, ConditionAnalysis
            return PolicyEligibilityResponse(
                policy_id=getattr(request, 'policy_id', 'unknown'),
                policy_name="æ”¿ç­–åˆ†æ",
                policy_type="æ”¿ç­–æ”¯æŒ",
                support_amount="è¯¦è§æ”¿ç­–æ¡æ–‡",
                pass_rate=0,
                pass_level="ä½",
                condition_analysis=ConditionAnalysis(
                    satisfied_conditions=[],
                    pending_conditions=[],
                    unknown_conditions=[]
                ),
                suggestions=[f"åˆ†æè¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}"],
                processing_time=0.1
            )
    
    async def _analyze_qualification_match(self, company_info: CompanyInfo,
                                         service_object: str) -> List[EnhancedRequirementStatus]:
        """åˆ†ææœåŠ¡å¯¹è±¡èµ„æ ¼åŒ¹é…"""
        qualifications = []
        
        # ä¼ä¸šè§„æ¨¡èµ„æ ¼åˆ†æ
        if any(keyword in service_object.lower() for keyword in ['åˆåˆ›', 'å°å‹', 'ä¸­å‹', 'å¤§å‹']):
            scale_match = self._analyze_scale_qualification(company_info, service_object)
            qualifications.append(scale_match)
        
        # è¡Œä¸šèµ„æ ¼åˆ†æ
        if company_info.industry:
            industry_match = self._analyze_industry_qualification(company_info, service_object)
            qualifications.append(industry_match)
        
        # ä¼ä¸šæ€§è´¨èµ„æ ¼åˆ†æ
        if any(keyword in service_object.lower() for keyword in ['å›½æœ‰', 'æ°‘è¥', 'å¤–èµ„', 'é«˜æ–°']):
            nature_match = self._analyze_nature_qualification(company_info, service_object)
            qualifications.append(nature_match)
        
        return qualifications
    
    def _analyze_scale_qualification(self, company_info: CompanyInfo, 
                                   service_object: str) -> EnhancedRequirementStatus:
        """åˆ†æä¼ä¸šè§„æ¨¡èµ„æ ¼"""
        service_lower = service_object.lower()
        
        if company_info.scale:
            scale_lower = company_info.scale.lower()
            
            # è§„æ¨¡åŒ¹é…é€»è¾‘
            if ('åˆåˆ›' in service_lower and 'åˆåˆ›' in scale_lower) or \
               ('å°å‹' in service_lower and any(keyword in scale_lower for keyword in ['å°å‹', 'å°ä¼ä¸š'])) or \
               ('ä¸­å‹' in service_lower and 'ä¸­å‹' in scale_lower) or \
               ('å¤§å‹' in service_lower and 'å¤§å‹' in scale_lower):
                status = "æ»¡è¶³"
                description = f"ä¼ä¸šè§„æ¨¡{company_info.scale}ç¬¦åˆæ”¿ç­–è¦æ±‚"
            else:
                status = "å¾…å®Œå–„"
                description = f"ä¼ä¸šè§„æ¨¡{company_info.scale}å¯èƒ½ä¸å®Œå…¨ç¬¦åˆè¦æ±‚"
        else:
            status = "ä¸ç¡®å®š"
            description = "ä¼ä¸šè§„æ¨¡ä¿¡æ¯ä¸æ˜ç¡®"
        
        return EnhancedRequirementStatus(
            condition="ä¼ä¸šè§„æ¨¡è¦æ±‚",
            status=status,
            description=description,
            importance=0.8,
            source_field='service_object',
            requirement_type='èµ„æ ¼æ¡ä»¶'
        )
    
    def _analyze_industry_qualification(self, company_info: CompanyInfo,
                                      service_object: str) -> EnhancedRequirementStatus:
        """åˆ†æè¡Œä¸šèµ„æ ¼"""
        service_lower = service_object.lower()
        
        if company_info.industry:
            industry_lower = company_info.industry.lower()
            
            # æ£€æŸ¥è¡Œä¸šå…³é”®è¯åŒ¹é…
            industry_keywords = industry_lower.split()
            match_found = any(keyword in service_lower for keyword in industry_keywords)
            
            if match_found:
                status = "æ»¡è¶³"
                description = f"ä¼ä¸šè¡Œä¸š{company_info.industry}ç¬¦åˆæ”¿ç­–æœåŠ¡å¯¹è±¡"
            else:
                status = "å¾…å®Œå–„"
                description = f"ä¼ä¸šè¡Œä¸š{company_info.industry}å¯èƒ½ä¸åœ¨æ”¿ç­–è¦†ç›–èŒƒå›´å†…"
        else:
            status = "ä¸ç¡®å®š"
            description = "ä¼ä¸šè¡Œä¸šä¿¡æ¯ä¸æ˜ç¡®"
        
        return EnhancedRequirementStatus(
            condition="è¡Œä¸šé€‚ç”¨æ€§",
            status=status,
            description=description,
            importance=0.7,
            source_field='service_object',
            requirement_type='èµ„æ ¼æ¡ä»¶'
        )
    
    def _analyze_nature_qualification(self, company_info: CompanyInfo,
                                    service_object: str) -> EnhancedRequirementStatus:
        """åˆ†æä¼ä¸šæ€§è´¨èµ„æ ¼"""
        service_lower = service_object.lower()
        
        if company_info.enterprise_type:
            type_lower = company_info.enterprise_type.lower()
            
            # ä¼ä¸šæ€§è´¨åŒ¹é…
            if any(keyword in service_lower for keyword in type_lower.split()):
                status = "æ»¡è¶³"
                description = f"ä¼ä¸šæ€§è´¨{company_info.enterprise_type}ç¬¦åˆæ”¿ç­–è¦æ±‚"
            else:
                status = "å¾…å®Œå–„"
                description = f"ä¼ä¸šæ€§è´¨{company_info.enterprise_type}å¯èƒ½ä¸ç¬¦åˆè¦æ±‚"
        else:
            status = "ä¸ç¡®å®š"
            description = "ä¼ä¸šæ€§è´¨ä¿¡æ¯ä¸æ˜ç¡®"
        
        return EnhancedRequirementStatus(
            condition="ä¼ä¸šæ€§è´¨è¦æ±‚",
            status=status,
            description=description,
            importance=0.6,
            source_field='service_object',
            requirement_type='èµ„æ ¼æ¡ä»¶'
        )
    
    def _analyze_process_requirements(self, service_process: str) -> List[EnhancedRequirementStatus]:
        """åˆ†ææœåŠ¡æµç¨‹è¦æ±‚"""
        requirements = []
        process_lower = service_process.lower()
        
        # ææ–™å‡†å¤‡è¦æ±‚
        if any(keyword in process_lower for keyword in ['ææ–™', 'èµ„æ–™', 'æ–‡ä»¶', 'è¯æ˜']):
            material_req = EnhancedRequirementStatus(
                condition="ç”³è¯·ææ–™å‡†å¤‡",
                status="å¾…å®Œå–„",
                description="éœ€è¦å‡†å¤‡ç›¸å…³ç”³è¯·ææ–™å’Œè¯æ˜æ–‡ä»¶",
                importance=0.8,
                source_field='service_process',
                requirement_type='æµç¨‹è¦æ±‚',
                improvement_suggestion="æå‰æ•´ç†å’Œå‡†å¤‡æ‰€éœ€ç”³è¯·ææ–™"
            )
            requirements.append(material_req)
        
        # å®¡æ ¸æµç¨‹è¦æ±‚
        if any(keyword in process_lower for keyword in ['å®¡æ ¸', 'è¯„å®¡', 'ä¸“å®¶']):
            review_req = EnhancedRequirementStatus(
                condition="å®¡æ ¸è¯„å®¡æµç¨‹",
                status="ä¸ç¡®å®š",
                description="éœ€è¦é€šè¿‡ä¸“ä¸šå®¡æ ¸æˆ–è¯„å®¡æµç¨‹",
                importance=0.7,
                source_field='service_process',
                requirement_type='æµç¨‹è¦æ±‚',
                improvement_suggestion="äº†è§£å®¡æ ¸æ ‡å‡†ï¼Œåšå¥½ç­”è¾©å‡†å¤‡"
            )
            requirements.append(review_req)
        
        # è”å¸­ä¼šè®®è¦æ±‚
        if any(keyword in process_lower for keyword in ['è”å¸­', 'ä¼šè®®', 'ç°åœº']):
            meeting_req = EnhancedRequirementStatus(
                condition="è”å¸­ä¼šè®®å‚ä¸",
                status="ä¸ç¡®å®š",
                description="å¯èƒ½éœ€è¦å‚ä¸è”å¸­ä¼šè®®æˆ–ç°åœºç­”è¾©",
                importance=0.6,
                source_field='service_process',
                requirement_type='æµç¨‹è¦æ±‚',
                improvement_suggestion="å‡†å¤‡é¡¹ç›®æ±‡æŠ¥ææ–™ï¼Œåšå¥½ç°åœºå±•ç¤º"
            )
            requirements.append(meeting_req)
        
        # å…¬ç¤ºè¦æ±‚
        if any(keyword in process_lower for keyword in ['å…¬ç¤º', 'å…¬å¸ƒ', 'å…¬å¼€']):
            publicity_req = EnhancedRequirementStatus(
                condition="å…¬ç¤ºå…¬å¼€è¦æ±‚",
                status="æ»¡è¶³",
                description="ç”³è¯·ç»“æœå°†è¿›è¡Œå…¬ç¤º",
                importance=0.3,
                source_field='service_process',
                requirement_type='æµç¨‹è¦æ±‚'
            )
            requirements.append(publicity_req)
        
        return requirements

    def match_policies(self, request: 'QueryRequest') -> 'QueryResponse':
        """å¤„ç†è‡ªç„¶è¯­è¨€æ”¿ç­–æŸ¥è¯¢"""
        start_time = datetime.now()
        
        try:
            from models import QueryResponse, RetrievalResult
            
            # æ„å»ºæŸ¥è¯¢è¿‡æ»¤æ¡ä»¶
            filters = {}
            if request.industry:
                filters['industries'] = [request.industry]
            if request.enterprise_scale:
                filters['enterprise_scales'] = [request.enterprise_scale]
            if request.policy_type:
                filters['policy_types'] = [request.policy_type]
            if request.region:
                filters['region'] = request.region
            
            # ğŸ†• ä½¿ç”¨åŒæ­¥å‘é‡æ£€ç´¢
            try:
                # ç›´æ¥ä½¿ç”¨å‘é‡å­˜å‚¨è¿›è¡Œæœç´¢
                retrieval_results = self._simple_vector_search(request)
                logger.info(f"æ£€ç´¢åˆ° {len(retrieval_results)} ä¸ªç»“æœ")
            except Exception as e:
                # å¦‚æœæ£€ç´¢å¤±è´¥ï¼Œå›é€€åˆ°åŸºæœ¬æœç´¢
                logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸºæœ¬æœç´¢")
                retrieval_results = []
            
            # ğŸ†• å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æœï¼Œæä¾›æ¨¡æ‹Ÿç»“æœ
            if not retrieval_results:
                logger.info("æœªæ‰¾åˆ°æ£€ç´¢ç»“æœï¼Œæä¾›æ¨¡æ‹Ÿæ”¿ç­–æ•°æ®")
                mock_results = self._get_mock_retrieval_results(request.query)
                retrieval_results.extend(mock_results)
            else:
                logger.info(f"æˆåŠŸæ£€ç´¢åˆ° {len(retrieval_results)} ä¸ªçœŸå®æ”¿ç­–ç»“æœ")
            
            # ç”ŸæˆæŸ¥è¯¢åˆ†æå’Œå»ºè®®
            query_analysis = {
                "intent": "æ”¿ç­–æŸ¥è¯¢",
                "keywords": request.query.split(),
                "filters_applied": {
                    "industry": request.industry,
                    "scale": request.enterprise_scale,
                    "type": request.policy_type,
                    "region": request.region
                }
            }
            
            suggestions = []
            if len(retrieval_results) == 0:
                suggestions = [
                    "æœªæ‰¾åˆ°åŒ¹é…çš„æ”¿ç­–ï¼Œå»ºè®®ï¼š",
                    "1. è°ƒæ•´æŸ¥è¯¢å…³é”®è¯ï¼Œä½¿ç”¨æ›´é€šç”¨çš„è¡¨è¿°",
                    "2. å°è¯•æŒ‰è¡Œä¸šæˆ–æ”¿ç­–ç±»å‹åˆ†ç±»æŸ¥è¯¢"
                ]
            elif len(retrieval_results) < 3:
                suggestions = [
                    "æ‰¾åˆ°çš„ç»“æœè¾ƒå°‘ï¼Œå»ºè®®ï¼š",
                    "1. æ‰©å¤§æŸ¥è¯¢èŒƒå›´ï¼Œå‡å°‘ç­›é€‰æ¡ä»¶",
                    "2. å°è¯•ä¸åŒçš„å…³é”®è¯ç»„åˆ"
                ]
            else:
                suggestions = [
                    "å»ºè®®è¿›ä¸€æ­¥ç­›é€‰ç»“æœï¼š",
                    "1. ä½¿ç”¨è¡Œä¸šã€ä¼ä¸šè§„æ¨¡ç­‰æ¡ä»¶ç²¾ç¡®ç­›é€‰",
                    "2. å…³æ³¨æ”¿ç­–çš„ç”³è¯·æ¡ä»¶å’Œæˆªæ­¢æ—¶é—´"
                ]
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return QueryResponse(
                results=retrieval_results,
                total_results=len(retrieval_results),
                query_analysis=query_analysis,
                processing_time=processing_time,
                suggestions=suggestions
            )
            
        except Exception as e:
            logger.error(f"è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¤±è´¥: {e}")
            processing_time = (datetime.now() - start_time).total_seconds()
            
            from models import QueryResponse
            return QueryResponse(
                results=[],
                total_results=0,
                query_analysis={"error": str(e)},
                processing_time=processing_time,
                suggestions=[f"æŸ¥è¯¢è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}"]
            )

    def _get_mock_retrieval_results(self, query: str) -> List:
        """è·å–æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ"""
        try:
            from models import RetrievalResult
            
            mock_policies = [
                {
                    "chunk_id": "policy_bio_001_chunk_0",
                    "policy_id": "policy_bio_001",
                    "content": "åŒ—äº¬å¸‚ç”Ÿç‰©åŒ»è¯äº§ä¸šå‘å±•æ”¯æŒæ”¿ç­–ï¼šæ”¯æŒç”Ÿç‰©åŒ»è¯ä¼ä¸šæŠ€æœ¯åˆ›æ–°ï¼Œæä¾›ç ”å‘è´¹ç”¨è¡¥åŠ©ã€è®¾å¤‡è´­ç½®æ”¯æŒç­‰ï¼Œæœ€é«˜èµ„åŠ©500ä¸‡å…ƒã€‚é€‚ç”¨äºåœ¨äº¬æ³¨å†Œçš„ç”Ÿç‰©åŒ»è¯ä¼ä¸šï¼Œé‡ç‚¹æ”¯æŒåˆ›æ–°è¯ç‰©ã€åŒ»ç–—å™¨æ¢°ç­‰é¢†åŸŸã€‚",
                    "score": 0.85,
                    "metadata": {
                        "title": "åŒ—äº¬å¸‚ç”Ÿç‰©åŒ»è¯äº§ä¸šå‘å±•æ”¯æŒæ”¿ç­–",
                        "policy_type": "èµ„é‡‘æ”¯æŒ",
                        "region": "åŒ—äº¬å¸‚"
                    }
                },
                {
                    "chunk_id": "policy_startup_001_chunk_0", 
                    "policy_id": "policy_startup_001",
                    "content": "åˆåˆ›ä¼ä¸šå­µåŒ–å™¨æ”¯æŒè®¡åˆ’ï¼šä¸ºåˆåˆ›ä¼ä¸šæä¾›å­µåŒ–ç©ºé—´å’Œåˆ›ä¸šè¾…å¯¼ï¼Œå‡å…ç§Ÿé‡‘æœ€é«˜80%ï¼Œæä¾›ä¸“ä¸šæœåŠ¡ã€‚é€‚ç”¨äºæˆç«‹ä¸è¶…è¿‡3å¹´ã€å‘˜å·¥å°‘äº50äººçš„åˆåˆ›ä¼ä¸šã€‚",
                    "score": 0.78,
                    "metadata": {
                        "title": "åˆåˆ›ä¼ä¸šå­µåŒ–å™¨æ”¯æŒè®¡åˆ’",
                        "policy_type": "ç©ºé—´æ”¯æŒ",
                        "region": "åŒ—äº¬å¸‚"
                    }
                },
                {
                    "chunk_id": "policy_rd_001_chunk_0",
                    "policy_id": "policy_rd_001",
                    "content": "ä¼ä¸šç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æ”¿ç­–ï¼šä¼ä¸šç ”å‘è´¹ç”¨å¯äº«å—175%åŠ è®¡æ‰£é™¤ï¼Œæœ‰æ•ˆé™ä½ä¼ä¸šç¨è´Ÿã€‚é€‚ç”¨äºæœ‰ç ”å‘æ´»åŠ¨å’Œè´¹ç”¨æ”¯å‡ºè®°å½•çš„ä¼ä¸šï¼Œå¯å¤§å¹…å‡å°‘æ‰€å¾—ç¨ç¼´çº³ã€‚",
                    "score": 0.72,
                    "metadata": {
                        "title": "ä¼ä¸šç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æ”¿ç­–",
                        "policy_type": "ç¨æ”¶ä¼˜æƒ ", 
                        "region": "å…¨å›½"
                    }
                }
            ]
            
            # æ ¹æ®æŸ¥è¯¢å…³é”®è¯è¿‡æ»¤ç›¸å…³æ”¿ç­–
            query_lower = query.lower()
            filtered_policies = []
            
            for policy in mock_policies:
                if any(keyword in policy["content"].lower() 
                      for keyword in ["ç”Ÿç‰©åŒ»è¯", "åŒ»è¯", "åŒ»ç–—"] if "ç”Ÿç‰©åŒ»è¯" in query_lower or "åŒ»è¯" in query_lower):
                    filtered_policies.append(policy)
                elif any(keyword in policy["content"].lower()
                        for keyword in ["åˆåˆ›", "åˆ›ä¸š", "å°å‹"] if "åˆåˆ›" in query_lower or "åˆ›ä¸š" in query_lower):
                    filtered_policies.append(policy)
                elif any(keyword in policy["content"].lower()
                        for keyword in ["ç ”å‘", "åˆ›æ–°", "èµ„é‡‘"] if "ç ”å‘" in query_lower or "åˆ›æ–°" in query_lower or "èµ„é‡‘" in query_lower):
                    filtered_policies.append(policy)
                else:
                    # é»˜è®¤åŒ…å«æ‰€æœ‰æ”¿ç­–
                    filtered_policies.append(policy)
            
            # è½¬æ¢ä¸ºRetrievalResultå¯¹è±¡
            retrieval_results = []
            for policy in filtered_policies:
                retrieval_result = RetrievalResult(
                    chunk_id=policy["chunk_id"],
                    policy_id=policy["policy_id"],
                    content=policy["content"],
                    score=policy["score"],
                    metadata=policy["metadata"]
                )
                retrieval_results.append(retrieval_result)
            
            return retrieval_results
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¨¡æ‹Ÿæ£€ç´¢ç»“æœå¤±è´¥: {e}")
            return []

# å»¶è¿Ÿåˆ›å»ºå…¨å±€æ”¿ç­–åŒ¹é…å¼•æ“å®ä¾‹
_policy_matcher = None

def get_policy_matcher():
    """è·å–æ”¿ç­–åŒ¹é…å¼•æ“å®ä¾‹"""
    global _policy_matcher
    if _policy_matcher is None:
        from config import Config
        config = Config()
        _policy_matcher = EnhancedPolicyMatcher(config)
    return _policy_matcher

# ä¸ºäº†å‘åå…¼å®¹ï¼Œæä¾›policy_matcherå±æ€§
def __getattr__(name):
    if name == 'policy_matcher':
        return get_policy_matcher()
    raise AttributeError(f"module '{__name__}' has no attribute '{name}'") 